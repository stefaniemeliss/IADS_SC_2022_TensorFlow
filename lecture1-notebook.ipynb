{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 1 notebook\n",
    "## Introduction to TensorFlow and Deep Learning\n",
    "\n",
    "## IADS Summer School, 1st August 2022\n",
    "\n",
    "### Dr Michael Fairbank, University of Essex, UK\n",
    "\n",
    "- Email: m.fairbank@essex.ac.uk\n",
    "- This is a Jupyter Notebook to accompany Lecture 1 of the course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Check Python engine is running\n",
    "\n",
    "You need to check you are on python 3.6 or above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n",
      "Python Version 3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello World\")\n",
    "import sys\n",
    "print(\"Python Version\",sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check tensorflow version\n",
    "\n",
    "You should see a version > 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "# importing tensorflow might take a while"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture slide content for Basic Concepts\n",
    "\n",
    "- Copy the lecture slide contents into the appropriate cells below, run each code block, and check you get the right answer.\n",
    "- There is no need to keep up with all of these in time with the lecture - just do the ones you are curious about for now.  Priorise keeping listening with the lecture and come back to any gaps later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Slide Title: Basic concepts- Tensor scalars, and numpy\n",
    "# Code (TODO)...\n",
    "a=tf.constant(2,tf.float32) # rank-0 tensor (i.e. a scalar) of type float32 with value of 2\n",
    "print(a)\n",
    "b=tf.constant(3,tf.float32) # rank-0 tensor (i.e. a scalar) of type float32 with value of 3\n",
    "print(b)\n",
    "c=tf.add(a,b) # addition\n",
    "print(c) # This just says c is a Tensor of shape() (rank zero), type float32, with value 5.0\n",
    "print(c.numpy()) # Converts from tensorflow datatype to a numpy datatype (apparently without loading numpy explicitely)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32) tf.Tensor(\n",
      "[[5 6]\n",
      " [8 9]], shape=(2, 2), dtype=int32)\n",
      "[[ 6  8]\n",
      " [11 13]]\n"
     ]
    }
   ],
   "source": [
    "# Slide Title: Basic concepts – tensor addition\n",
    "# Code (TODO)...\n",
    "a=tf.constant([[1,2],[3,4]])\n",
    "b=tf.constant([[5,6],[8,9]])\n",
    "print(a,\n",
    "      b)\n",
    "c=tf.add(a,b)\n",
    "print(c.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "[[5 6]\n",
      " [8 9]]\n",
      "[[ 5 12]\n",
      " [24 36]]\n"
     ]
    }
   ],
   "source": [
    "# Slide Title: Basic concepts – tensor multiplication \n",
    "# Code (TODO)...\n",
    "a=tf.constant([[1,2],[3,4]])\n",
    "b=tf.constant([[5,6],[8,9]])\n",
    "c=tf.multiply(a,b) # Elementwise multiplication (“Hadamard product”)\n",
    "print(a.numpy())\n",
    "print(b.numpy())\n",
    "print(c.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2.]\n",
      " [3. 4.]]\n",
      "[[1.]\n",
      " [1.]]\n",
      "[[3.]\n",
      " [7.]]\n"
     ]
    }
   ],
   "source": [
    "# Slide Title: Basic concepts – matrix multiplication \n",
    "# Code (TODO)...\n",
    "a=tf.constant([[1,2],[3,4]],tf.float32) # A rank-2 tensor (i.e. a 2*2 matrix)\n",
    "print(a.numpy())\n",
    "b=tf.constant([[1],[1]], tf.float32) # A rank-2 tensor (a 2*1 matrix)\n",
    "print(b.numpy())\n",
    "c=tf.matmul(a,b) # Matrix multiplication\n",
    "print(c.numpy())\n",
    "\n",
    "# Matrix multiplication\n",
    "# [[1 2]    [[1]    [[1*1 + 1*2]    [3]\n",
    "          *       =               =\n",
    "#  [3 4]]    [1]]    [1*3 + 1*4]]   [7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3.2, shape=(), dtype=float32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(5.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Slide Title: Basic concepts – datatypes: https://www.tensorflow.org/api_docs/python/tf/dtypes/DType\n",
    "# Code (TODO)...\n",
    "a=tf.constant(3.2, tf.float32)\n",
    "print(a)\n",
    "b=tf.constant(3, tf.int32)\n",
    "print(b)\n",
    "c=tf.constant([1,2,3], tf.float32)\n",
    "print(c)\n",
    "d=tf.constant(5) # This defaults to int32\n",
    "print(d)\n",
    "tf.constant(5.0) # This defaults to float32\n",
    "print(e)\n",
    "\n",
    "# Also have tf.float64, tf.int64, tf.bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2]\n",
      " [ 3 -4]]\n",
      "[1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Slide Title: Basic concepts – casting datatypes (1): convert one datatype to another\n",
    "# Code (TODO)...\n",
    "a=tf.constant([[1,2],[3,-4]],tf.float32)\n",
    "print(tf.cast(a,tf.int32).numpy()) # This is now an integer tensor\n",
    "\n",
    "b=tf.constant([True, False, True], tf.bool)\n",
    "print(tf.cast(b,tf.int32).numpy()) # Bools cast using True=1, False=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:AddV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_32\\1088066776.py\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Python3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7162\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7163\u001b[0m   \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7164\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:AddV2]"
     ]
    }
   ],
   "source": [
    "# Slide Title: Basic concepts – casting datatypes (2)\n",
    "# Code (TODO)...\n",
    "# You can’t add datatypes that don’t match --> code will produce error\n",
    "a=tf.constant(3.0, tf.float32)\n",
    "b=tf.constant(3, tf.int32)\n",
    "c=tf.add(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n"
     ]
    }
   ],
   "source": [
    "# we have to cast it like this\n",
    "c=tf.add(a,tf.cast(b,tf.float32))\n",
    "print(c.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [2] vs. [3] [Op:AddV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_32\\1099500921.py\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Python3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7162\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7163\u001b[0m   \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7164\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [2] vs. [3] [Op:AddV2]"
     ]
    }
   ],
   "source": [
    "# Slide Title: Basic concepts – tensor shape (1): Tensor shapes must match for most operations\n",
    "# Code (TODO)...\n",
    "# code will produce error\n",
    "a=tf.constant([1,2])\n",
    "b=tf.constant([2,3,1])\n",
    "f=tf.add(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However there is a shorthand that violates these size-matching rules  \n",
    "When the rank of one matrix is less than the other it tries to add them in  the most sensible way (if possible)  \n",
    "  \n",
    "this behaviour is called “broadcasting”: https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slide Title: Basic concepts – tensor shape (2)\n",
    "# Code (TODO)...\n",
    "a=tf.constant([1,2])\n",
    "b=tf.constant(1)\n",
    "print(tf.add(a,b).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slide Title: Basic concepts – tensor shape (3)\n",
    "# Code (TODO)...\n",
    "a=tf.constant([[1,2],[3,4]])\n",
    "b=tf.constant([10,20])\n",
    "print(tf.add(a,b).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  4.]\n",
      " [ 9. 16.]]\n",
      "[[1. 2.]\n",
      " [3. 4.]]\n",
      "[[ 0.7615942  0.9640276]\n",
      " [ 0.9950547 -0.9993292]]\n"
     ]
    }
   ],
   "source": [
    "# Slide Title: Elementwise Tensor operations\n",
    "# Code (TODO)...\n",
    "# These elementwise operations produce a tensor of equal size to the input\n",
    "\n",
    "a=tf.constant([[1,2],[3,-4]],tf.float32)\n",
    "print(tf.square(a).numpy())\n",
    "print(tf.abs(a).numpy())\n",
    "\n",
    "print(tf.tanh(a).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True False]\n",
      "[False  True  True]\n"
     ]
    }
   ],
   "source": [
    "# Slide Title: Comparison Tensor operations: https://www.tensorflow.org/api_docs/python/tf/math/greater\n",
    "# Code (TODO)...\n",
    "\n",
    "a=tf.constant([1,2,3])\n",
    "b=tf.constant([5,1,7])\n",
    "print(tf.greater(a,b).numpy())\n",
    "\n",
    "print(tf.greater(a,1).numpy()) # This is “broadcasting” the mismatching tensor sizes, i.e., changing 1 to [1,1,1] before comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  8]\n",
      " [11 13]]\n",
      "[[ 5 12]\n",
      " [24 36]]\n",
      "[[21 24]\n",
      " [47 54]]\n"
     ]
    }
   ],
   "source": [
    "# Slide Title: Basic concepts – operator shorthand\n",
    "# Code (TODO)...\n",
    "# a+b --> tf.add(a,b)\n",
    "# a-b --> tf.subtract(a,b)\n",
    "# a*b --> tf.multiply(a,b) \n",
    "# a@b --> tf.matmul(a,b)\n",
    "# a>b --> tf.greater(a,b)\n",
    "\n",
    "a=tf.constant([[1,2],[3,4]])\n",
    "b=tf.constant([[5,6],[8,9]])\n",
    "print((a+b).numpy())\n",
    "print((a*b).numpy())\n",
    "print((a@b).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.]\n",
      "[-1.]\n"
     ]
    }
   ],
   "source": [
    "# Slide Title: Basic concepts – variables vs. constants (1): \n",
    "# Code (TODO)...\n",
    "# Unlike “constants”, all “Variables” can be updated. \n",
    "W = tf.Variable([0.3], tf.float32)\n",
    "W.assign([-1.0])\n",
    "print(W.numpy())\n",
    "\n",
    "# Constants however, once created, cannot be “reassigned”\n",
    "x = tf.constant([0.3], tf.float32)\n",
    "x = tf.constant([-1], tf.float32)\n",
    "print(x.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.3]\n",
      "[0.29999995]\n"
     ]
    }
   ],
   "source": [
    "# Slide Title: Basic concepts – variables vs. constants (2): Variables also have assign_add and assign_sub\n",
    "# Code (TODO)...\n",
    "W = tf.Variable([0.3], tf.float32)\n",
    "W.assign_add([1.0]) # Analogous to W+=1\n",
    "print(W.numpy())\n",
    "W.assign_sub([1.0])\n",
    "print(W.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "2.5\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "# Slide Title: Aggregation functions (1)\n",
    "# Code (TODO)...\n",
    "a=tf.constant([[1,2],[3,4]],tf.float32)\n",
    "print(tf.reduce_sum(a).numpy()) # sums up all values in the tensor and REDUCES it to a single number\n",
    "print(tf.reduce_mean(a).numpy()) # computes mean of all values in tensor\n",
    "print(tf.reduce_max(a).numpy()) # computes max of all values in tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n"
     ]
    }
   ],
   "source": [
    "# Slide Title: Aggregation functions (2)\n",
    "# Code (TODO)...\n",
    "a=tf.constant([[1,2],[3,4]],tf.float32)\n",
    "print(tf.reduce_sum(tf.cast(a>1,tf.float32)).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Slide Title: Aggregation functions (3)\n",
    "# Code (TODO)...\n",
    "a=tf.constant([4,0,5,-4],tf.float32)\n",
    "print(tf.reduce_max(a).numpy())\n",
    "print(tf.argmax(a).numpy()) # Argmax counts the **index** at which the max element appears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 6]\n",
      "[3 7]\n"
     ]
    }
   ],
   "source": [
    "# Slide Title: Aggregation functions across an axis (1)\n",
    "# Code (TODO)...\n",
    "a=tf.constant([[1,2],[3,4]])\n",
    "print(tf.reduce_sum(a, axis=0).numpy()) # columns\n",
    "print(tf.reduce_sum(a, axis=1).numpy()) # rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5 10 12]\n",
      "[1 2]\n"
     ]
    }
   ],
   "source": [
    "# Slide Title: Aggregation functions across an axis (2)\n",
    "# Code (TODO)...\n",
    "a=tf.constant([[5,10,0],[3,4,12]])\n",
    "print(tf.reduce_max(a, axis=0).numpy())\n",
    "print(tf.argmax(a, axis=1).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic differentiation\n",
    "\n",
    "Autodiff is fast and exact differentiation\n",
    "- Not numerical differentiation (which is neither exact nor fast)\n",
    "- Not symbolic differentiation either\n",
    "- it’s something in between\n",
    "- If you give it code to compute a function f(x), it will write corresponding program code for you that calculated df/dx\n",
    "  \n",
    "https://justindomke.wordpress.com/2009/02/17/automatic-differentiation-the-most-criminally-underused-tool-in-the-potential-machine-learning-toolbox/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n"
     ]
    }
   ],
   "source": [
    "# Slide Title: Automatic differentiation (Autodiff) (1)\n",
    "# Code (TODO)...\n",
    "x = tf.Variable(3.0, tf.float32)\n",
    "with tf.GradientTape() as tape:\n",
    "    y=tf.pow(x,2.0)\n",
    "    dydx=tape.gradient(y, x)\n",
    "print(dydx.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autodiff also works when there is more than one input variable:  \n",
    "https://en.m.wikipedia.org/wiki/Partial_derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.0 1.0\n"
     ]
    }
   ],
   "source": [
    "# Slide Title: Automatic differentiation (Autodiff) (3)\n",
    "# Code (TODO)...\n",
    "x=tf.Variable(4.0,tf.float32)\n",
    "y=tf.Variable(2.0,tf.float32)\n",
    "with tf.GradientTape() as tape:\n",
    "    f=tf.pow(x,2.0)*3.0+y\n",
    "[dfdx, dfdy]=tape.gradient(f, [x,y]) # Fetching two derivatives at once\n",
    "print(dfdx.numpy(), dfdy.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want a derivative w.r.t. a constant, then you need tape.watch(…)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autodiff also works when the input variables are higher rank tensors.  \n",
    "AUTODIFF makes neural-network training much easier to program\n",
    "- Autodiff replaces “backpropagation” programming\n",
    "- Backpropagation is replaced by autodiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.0\n"
     ]
    }
   ],
   "source": [
    "# Slide Title: Automatic differentiation (Autodiff) (4)\n",
    "# Code (TODO)...\n",
    "x=tf.constant(4.0,tf.float32) # A “constant” requires watching\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x) # A “constant” requires watching\n",
    "    f=tf.pow(x,3.0)\n",
    "dfdx=tape.gradient(f, x)\n",
    "print(dfdx.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent Exercise\n",
    "\n",
    "- In this exercise we will build a gradient descent script to minimise $y = x^2 − 4x + 4$ with respect to $x$.\n",
    "- Please tackle this exercise carefully - this is the main exercise of this lecture!\n",
    "\n",
    "- Gradient Descents are an iterative process of algorithm optimisation where the minimum of x with respect to the function y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slide Title: Example 1D Gradient Descent problem\n",
    "# Complete the 3 TODOs below and run the code to solve the minimisation challenge...\n",
    "import tensorflow as tf\n",
    "eta = 0.1 # learning rate\n",
    "x = tf.Variable(10.0, tf.float32) # arbitrary initial value\n",
    "\n",
    "# Exercise 1: Use gradient descent to find the minimum of 𝑦 = 𝑥^2 − 4𝑥 + 4\n",
    "for i in range(50):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y=tf.pow(x,2.0)-tf.multiply(x,4)+4#TODO put in formula for y in terms of x here\n",
    "    dydx=tape.gradient(y,x)# TODO finish this line\n",
    "    x.assign(tf.subtract(x,tf.multiply(eta, dydx)))# TODO finish x_(t+1)=x_t-eta*dydx\n",
    "    # note: We didn’t need to give the iterative variable’s steps different variable names 𝑥1, 𝑥2, … We just called them all “x”\n",
    "    print(\"iteration:\",i, \"x:\", x.numpy(), \"y:\", y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimised versions of Gradient Descent Exercise\n",
    "\n",
    "- Now we will repeat the above exercise (and hopefully get exactly the same results again)\n",
    "- But now we will use some higher-level TensorFlow functions..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1, Version 2: @tf.function\n",
    "\n",
    "Inefficiency:\n",
    "- Recalculates the automatic differentiation formula every step of loop!\n",
    "  \n",
    "Fix this by:\n",
    "1. pulling out guts of main loop into a separate python function  \n",
    "    def do_update():\n",
    "2. Annotate this function by “@tf.function”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slide Title: Optimised Version (Exercise 1, Version 2)\n",
    "# Code (TODO)...\n",
    "import tensorflow as tf\n",
    "\n",
    "eta = 0.1 # learning rate\n",
    "x = tf.Variable(10.0, tf.float32) # arbitrary initial value\n",
    "\n",
    "@tf.function\n",
    "def do_update(x):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y=tf.pow(x,2.0)-4.0*x+4.0\n",
    "    dydx=tape.gradient(y, x)\n",
    "    x.assign(x-dydx*eta)\n",
    "    return y\n",
    "\n",
    "for i in range(50):\n",
    "    y=do_update(x)\n",
    "    print(\"iteration:\",i, \"x:\", x.numpy(), \"y:\", y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use function annotation @tf.function to speed up execution, take advantage of the GPU, and for saving models\n",
    "    - It allows tensorflow to cache the graph of computations so that it doesn’t have to recalculate them (or the derivatives) every iteration.\n",
    "- Adding the @tf.function in this task sped things up by around 4 times  \n",
    "- Put @tf.function around the main functionality of your training loop \n",
    "    - After you’ve debugged things\n",
    "    - Warning – the function you are optimising must not refer to any global variables (unless they are strictly constants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1, Version 3: Using a built-in optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slide Title: Using a built-in optimizer\n",
    "# Code (TODO)...\n",
    "import tensorflow as tf\n",
    "\n",
    "eta = 0.1 # learning rate\n",
    "x = tf.Variable(10.0, tf.float32) # arbitrary initial value\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(eta) # SGD = Stochastic Gradient Descent\n",
    "def calc_y():\n",
    "    y=tf.pow(x,2.0)-4.0*x+4.0\n",
    "    return y\n",
    "\n",
    "for i in range(50):\n",
    "    optimizer.minimize(calc_y, [x])\n",
    "    print(\"iteration:\",i, \"x:\", x.numpy(), \"y:\", calc_y().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other built-in optimizers work better with neural networks:\n",
    "- optimizer = tf.keras.optimizers.SGD(eta)\n",
    "- optimizer = tf.keras.optimizers.Adam()\n",
    "- optimizer = tf.keras.optimizers.RMSProp()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slide Title: Using a built-in optimizer\n",
    "# Code (TODO)...\n",
    "import tensorflow as tf\n",
    "\n",
    "x = tf.Variable(10.0, tf.float32) # arbitrary initial value\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "def calc_y():\n",
    "    y=tf.pow(x,2.0)-4.0*x+4.0\n",
    "    return y\n",
    "\n",
    "for i in range(50):\n",
    "    optimizer.minimize(calc_y, [x])\n",
    "    print(\"iteration:\",i, \"x:\", x.numpy(), \"y:\", calc_y().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## End of lecture 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
